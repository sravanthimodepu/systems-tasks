#+Title: Systems Tasks List
#+Author: Sravanthi
#+Date: [2018-08-03 Fri]

* Introduction
  This document contains the list of tasks for a system engineer at
  vlead.
* List od Tasks
  - backup-config-files
  - Ernet
  - [[https://gitlab.com/vlead-systems/docs/blob/master/src/how-to/renewal-ssl.org][SSL certificates]] - domain name provider need to renew everytime
    before its renew time.
  - vlead-projects/aws-invoices
  - Outreach-portal
  - Feedback-portal
  - Analytics   
* Admin Tasks
  - Custom in gmail groups??
  - Gmail a/c
  - Ldap
  - Github
  - Gitlab
  - bitbucket 
  - Public/private domain
  - *AWS*
** Passwords
   - Login to base1
   - Enter into 12151 container 
     #+BEGIN_EXAMPLE
     vzctl enter 12151
     su -
     #+END_EXAMPLE
   - sqiltepassword.txt - base machines passwords
   - To open password.txt give the encrypted key.
* Create vlabs gmail account
** User details
   - Ask a users to give their details such as
   - Name
   - Phone Number
   - Gmail account
   - Github & Gitlab handles	
** Vlabs gmail account 
   - Login to vlabs admin account
   - Select admin from the menu
   - Select users option in Admin console
   - Click on "+" button to create user.
   - Enter user information details and set password.
   - To delete a user, choose user and suspend. 
** Add user in vlead mailing groups
   - Select groups in Admin console
   - Choose a group, click on manage users in group
   - Enter user mail id and add.
   - To remove user from the group, select user and click on =Remove
     memeber=.
** List of vlead Mailing groups  
   - vlead-staff@vlabs.ac.in
   - vlead-employees@vlabs.ac.in
   - systems@vlabs.ac.in 
   - support@vlabs.ac.in 
   - engineers@vlabs.ac.in
* LDAP(Lightweight Directory Access Protocol) account creation
** Ldap credentials access 
   - GLPi
   - Base machines
   - Redmine
   - community
** Create ldap account for a user
   - Login to LDAP server on base3 with ldap user credentials.
     #+BEGIN_EXAMPLE
     ssh modepusravanthi@10.4.12.23
     sudo su -
     vzctl enter 13165
     su -
     #+END_EXAMPLE
   - Change directory to ldif_files(LDAP Data Interchange Format).
   - LDIF conveys directory content as a set of records, one record
     for each object.
   - create a file  =ldif_files/add_user_with_password.ldif= and add the below lines to it:
     #+BEGIN_EXAMPLE
     dn: cn=<user-name>,ou=people,dc=virtual-labs,dc=ac,dc=in  
     objectClass: inetOrgPerson
     objectClass: posixAccount
     objectClass: shadowAccount
     cn: <user-name>
     sn: <last-name>
     gn: <first-name>
     mail: <email-id>
     ou: people
     displayName: <user-name>
     telephoneNumber: <mobile-number>
     postalAddress:  IIIT-H 
     #Posix and Shadow account related attributes
     uid: <user-name>
     uidNumber: <some UID number above 500>
     gidNumber: <some GID number above 500> (same for all the user as it is group id)
     homeDirectory: /home/<user-name>
     loginShell: /bin/bash
     gecos: <user-name>
     userPassword: <slappasswd generated SSHA hash>
     shadowLastChange: 0
     shadowMax: -1
     shadowWarning: 999999
     #+END_EXAMPLE
   - set password for the created user with the below command:
     #+BEGIN_EXAMPLE
     slappasswd
     #+END_EXAMPLE
   - It generates the password for the user.  
   - Edit the add_user_with_password.ldif file, paste the generate
     password into userPassword place.
   - Add the user with LDAP
     #+BEGIN_EXAMPLE
     ldapadd -x -D 'cn=root,dc=virtual-labs,dc=ac,dc=in' -W -f add_user_with_password.ldif
     #+END_EXAMPLE
   - Remove user from group
   - Reset password
** Remove user from ldap
   - To remove a user's ldif file use below command and replace the
     text within < > with the LDAP user¡¯s information.
     #+BEGIN_EXAMPLE
     ldapdelete -x -D "cn=root,dc=virtual-labs,dc=ac,dc=in" -W "cn=<user-name>,ou=people,dc=virtual-labs,dc=ac,dc=in"
     #+END_EXAMPLE
** Add user in Ldap admin group
    - Create a file =ldif_files/user-to-admin-group.ldif-<data>=
    - Add the below lines to the file:
      #+BEGIN_EXAMPLE
      dn: cn=admin,ou=groups,dc=virtual-labs,dc=ac,dc=in
      changetype: modify
      add: memberuid
      memberuid: medhamsh
      #+END_EXAMPLE
    - Save the file and use the below command to add a user to admin group:
      #+BEGIN_EXAMPLE
      ldapadd -x -D 'cn=root,dc=virtual-labs,dc=ac,dc=in' -W -f add_user_into-admin-group.ldif
      #+END_EXAMPLE
** Remove user from vlead admin group
   - Create a file =ldif_files/remove_user_from-admin-group.ldif=. Add
     below lines and save the file.
     #+BEGIN_EXAMPLE
     dn: cn=admin,ou=groups,dc=virtual-labs,dc=ac,dc=in
     changetype: modify
     delete: memberuid
     memberuid: <user-id>
     #+END_EXAMPLE
   - Run the following command to remove user from admin group
     #+BEGIN_EXAMPLE
     ldapmodify -x -D "cn=root,dc=virtual-labs, dc=ac, dc=in" -W -f remove_user_group.ldif
     #+END_EXAMPLE
   - Enter LDAP password to remove user  
** Reset password
   - create a file =ldif_files/reset_user_password.ldif=. Add below
     lines and save the file
     #+BEGIN_EXAMPLE
     dn: cn=<user-name>,ou=people,dc=virtual-labs,dc=ac,dc=in  
     changetype: modify
     replace: userPassword
     userPassword: <slappasswd generated SSHA hash>
     #+END_EXAMPLE  
   - Use below command to modify the user
     #+BEGIN_EXAMPLE
     ldapmodify -x -D "cn=root,dc=virtual-labs,dc=ac,dc=in" -W -f ldif_files/reset_user_password.ldif
     #+END_EXAMPLE
   - Enter ldap password (from passwords.txt)
   - Use below command to generate a new password
     #+BEGIN_EXAMPLE
     slappasswd
     #+END_EXAMPLE
   - Edit the reset_user_password.ldif file, paste the generate
     password into userPassword place.
** Modify user  
    - Give github & gitlab access as vlead-staff & vlead organization
* Close the fixed issues 
    - Closing unnecessary/ fixed issues from gitlab systems-operations
      repository.
    - If the issue is fixed, close the issue. 
* Access to common folders
* OS installation
    - Configuration of a machine/system
    - Partition  
    - Installing Packages 
* Deployment
    - First deploy the lab on base4(testing environment) through
      ADS. It creates a container on base4, we can check the given lab
      url.
    - If everything works fine then deploy the lab on
      base1(staging/production) using ADS.
    - It creates an AMI, Instance, volume and snapshot at AWS with the
      size, ID, type, IP address.
** Deployment through ADS on base1, base4
   - Use below URL to deploy the lab on base4 & base1:
     #+BEGIN_EXAMPLE
     http://ads.base4.virtual-labs.ac.in/  - base4
     http://ads.base1.virtual-labs.ac.in/  - base1
     #+END_EXAMPLE
   - Ads main page is displayed, click on Login button.
   - It asks for gmail credentials.
   - After the successful authentication.
   - A page to submit lab-id, lab url is displayed.
   - Give lab-ID, githubURL of the lab and branch then click on submit
     button.
   - After submitting, the below steps are processed internally
     through the deployment.
   - Initially, it clones the repository in ads
   - Creates a contianer with - OStemplate, IP,hostname
   - Installs dependenices through labspec.json
   - Copy the repository from ads to contianer
   - Enter into container and run make.
   - Remove default file index.html from /var/www/html/
   - Then copy build folder to /var/www/html/
   - After the successfull deployment, it gives the Ipaddress.
   - Copy the given IP and paste it in the browser.
   - The lab will be displayed.  
** Production
   - Login to ssh-tunnel with the below command:
     #+BEGIN_EXAMPLE
     ssh user@ssh-tunnel.vlabs.ac.in
     sudo su -
     #+END_EXAMPLE
   - Login to ansible to make necessary changes to deploy a lab.
     #+BEGIN_EXAMPLE
     ssh -i aa1.pem vlead@ansible.vlabs.ac.in
     #+END_EXAMPLE
   - It asks passphrase for key =aa1.pem=  
   - cd git/systems-model/build/aws-code
   - vim roles/common_vars/vars/main.yml and Add/Delete
     public/private/reverse proxy entries with domain name.
   - ansible playbook -i hosts private/public/reverse-proxy.yml files.
   - login to base3 - ssh ldap@10.4.12.23
     #+BEGIN_EXAMPLE
     ssh ldap@10.4.12.23
     vzctl enter <public-dns>
     #+END_EXAMPLE
   - vim /var/named/virtual-labs.conf
   - Add public entry (domain name)
   - Run the below command to start named
     #+BEGIN_EXAMPLE
     service reload named
     #+END_EXAMPLE 
   - ssh root@reverseproxy.vlabs.ac.in
   - vim /etc/httpd/conf.d/virtual-hosts.conf
   - service httpd relaod
   - ssh root@public-dns
   - vi /var/named/vlabs.ac.in.forward/ virtual-labs.ac.in.forward
   - login to base3, enter into ns1-pub  
   - vi /var/named/vlabs.ac.in.forward/ virtual-labs.ac.in.forward
     #+BEGIN_EXAMPLE
     add domain name
     #+END_EXAMPLE
* Creating an OPenVZ container
    - One should install OpenVZ on centos/ubuntu.
    - Commands to create and start openvz container:
      #+BEGIN_EXAMPLE
      vzctl create <CTID> --ostemplate <ubuntu-14.04-X86_64> --ipaddress <10.4.12.30> --hostname <xxx.vlabs.ac.in>
      vzctl start <CTID>
      vzctl enter <CTID>
      #+END_EXAMPLE
    - Commands to stop and delete a container
      #+BEGIN_EXAMPLE
      vzctl stop <CTID>
      vzctl destroy <CTID>
      #+END_EXAMPLE
* ADS
    - Download ads vagrantbox from [[http://files.vlabs.ac.in/downloads/vagrant-boxes/ads-on-centos.box][here]]. 
    - Add downloaded vagrantbox to the vagrantbox list
    - create a folder and run =vagrant init= inside the folder.
    - It generates a =Vagrantfile=  
    - Open vagrant file and update =config.vim.box= as the the folder
      name which was created earlier.
    - Uncomment the =private_network= line the the same file.
    - Save and exit from the file.
    - Change directory to the folder and type below command to start and
      enter into the ads vagranbox.
      #+BEGIN_EXAMPLE
      vagrant up
      vagrant ssh
      #+END_EXAMPLE
    -   
    - Make appropriate changes and run the below scripts
      #+BEGIN_EXAMPLE
      ./managescript.sh
      python app.py &
      #+END_EXAMPLE
* College Cloud
    - Setup college cloud
    - cluster setup is college cloud
* IRC
   - IRc channel on base3 container ID 16302
   - Install and setup supybot
   - Create a user vlead and configure supybot inside the user.
   - Run "supybot vlead-logging.conf &" whenever IRC stops backing up the logs  
* Migrating containers 
  - Login to base4 choose the container you want to migrate from
    base4 to base3 and run the below command:
    #+BEGIN_EXAMPLE     
    vzmigrate <basemachine_ip> <CTID>
    Ex: vzmigrate 10.4.12.24 41
    #+END_EXAMPLE  
* Docker
* DNS
   - Domain Name Service (DNS) is an Internet service that maps IP
     addresses and fully qualified domain names (FQDN) to one
     another. In this way, DNS alleviates the need to remember IP
     addresses. Computers that run DNS are called name servers.
   - sudo apt install bind9
   - sudo apt install dnsutils
   - The DNS configuration files are stored in the /etc/bind
     directory. The primary configuration file is /etc/bind/named.conf
   - Login to base4 as below:
     #+BEGIN_EXAMPLE
     ssh <user>@10.4.12.24
     #+END_EXAMPLE
   - Login to the public-dns container as below:
     #+BEGIN_EXAMPLE
     vzctl enter 1006
     #+END_EXAMPLE
   - Open the file =/var/named/base4.virual-labs.ac.in.forward= and
     =/var/named/base4.vlabs.ac.in.forward=
   - Add the domain name of the lab to make the lab public.
   -   
* Bootstraping
  - Setting up the cluster using bootstrapping steps
  - The bootstraping steps configures the router, ansible, rsyslog,
      reverse-proxy, nagios,rsnapshot,ADS, privatedns, publicdns,
      ossec server manually.
  -  
* Cluster automation
    - The cluster automation implements the following with the
      =bootstrap.sh= shell script:
      #+BEGIN_EXAMPLE
      basic machine setup
      creates cluster containers
      router
      ansible/config server
      ossec-server
      rsyslog  server
      private-dns server
      public-dns server 
      reverse-proxy server
      nagios server
      rsnapshot server
      ADS service
      Main Playbook
      #+END_EXAMPLE
*** Steps for cluster automation      
    - Install a minimal centos in virtual box with the following
      configuration:
      #+BEGIN_EXAMPLE 
      RAM 1GB
      #+END_EXAMPLE 
    - Should be connected to the Lan cable 
    - Change the Network settings from =NAT to Bridge Adapter= and
      =Display= to minimum =50MB=.
    - Login to machine with root credentials.
    - Export network proxy and type =dhclient -v= to make the internet
      working state.
    - Install git with the below command:
      #+BEGIN_EXAMPLE
      yum install -y git
      #+END_EXAMPLE
    - Clone the cluster-automation repository
      #+BEGIN_EXAMPLE
      git clone https://gitlab.com/vlead-systems/cluster-automation
      #+END_EXAMPLE
    - Change directory to cluster-automation
    - Run make
    - Take three LAN IP's for hostmachine, router,config server  
    - **Edit the file
      ~/cluster-automation/build/code/imp/roles/common_vars/vars/main.yml
      and make the following changes:
      #+BEGIN_EXAMPLE
      hostmachine_ip: <>
      router_ip: <>
      config_server_ip: <>
      #+END_EXAMPLE
    - Change consumer key and consumer secret in the above file.  
    - Run bootstrap.sh file from cluster-automation directory.
    - After running the script all the servers are properly configured.

* Tasks to be Learn 
    - base machines down - solution   
    - vlabs-about
    - vlabs-dev-pages
    - Vlabs-web-pages
    - Nagios
    - Outreach portal
    - Feedback portal
    - All passwords
    - Experiment server
    - Migrating instances from t2.micro to t2.nano
    - SSL Certificates
    - vlabs Wiki
    - Servers Size increment
    - Server backup dump
    - reverseproxy - 80%
    - Nagios
    - Vagrant
    - Kernal
    - OS hardening  
* Important containers running on base3, base1
** Important contianers running on Base 3 
      =134         24 running   10.4.12.134     files.vlabs.ac.in=
      =135         45 running   10.4.12.135     glpi.vlabs.ac.in=
     12052          - stopped   10.4.12.52      cse04-iiith.virtual-labs.ac.in
     12053         43 running   10.4.12.53      cse06-iiith.virtual-labs.ac.in
     12054         41 running   10.4.12.54      cse07-iiith.virtual-labs.ac.in
     12055          - stopped   10.4.12.55      cse09-iiith.virtual-labs.ac.in
     12056         43 running   10.4.12.56      cse05-iiith.virtual-labs.ac.in
     12057         43 running   10.4.12.57      cse13-iiith.virtual-labs.ac.in
     12058         24 running   10.4.12.58      cse16-iiith.virtual-labs.ac.in
     12059         43 running   10.4.12.59      cse17-iiith.virtual-labs.ac.in
     12060         43 running   10.4.12.60      cse21-iiith.virtual-labs.ac.in
     12061         43 running   10.4.12.61      cse24-iiith.virtual-labs.ac.in
     12062         43 running   10.4.12.62      cse30-iiith.virtual-labs.ac.in
    =12063          - stopped   -               repo-backup.vlabs.ac.in=
     12064         43 running   10.4.12.64      eerc02-iiith.virtual-labs.ac.in
     12065          - stopped   10.4.12.65      eerc04-iiith.virtual-labs.ac.in
     12066         43 running   10.4.12.66      eerc05-iiith.virtual-labs.ac.in
     12067          - stopped   10.4.12.67      cse23-iiith.virtual-labs.ac.in
     12068         43 running   10.4.12.68      cse10-iitkgp.virtual-labs.ac.in
     12069         37 running   10.4.12.69      civil13-iitb.virtual-labs.ac.in
     12070          - stopped   10.4.12.70      ccnsb01-iiith.virtual-labs.ac.in
     12071         41 running   10.4.12.71      ccnsb02-iiith.virtual-labs.ac.in
     12072          - stopped   10.4.12.72      ccnsb03-iiith.virtual-labs.ac.in
     12073         43 running   10.4.12.73      ccnsb04-iiith.virtual-labs.ac.in
     12074         24 running   10.4.12.74      ccnsb05-iiith.virtual-labs.ac.in
     12075          - stopped   10.4.12.75      ccnsb07-iiith.virtual-labs.ac.in
     12079         24 running   10.4.12.79      mech01-iitg.virtual-labs.ac.in
     12080          - stopped   10.4.12.80      eee06-dei.virtual-labs.ac.in
    =12081         20 running   -               aws-backup.virtual-labs.ac.in=
    =12159         33 running   -               http.virtual-labs.ac.in=
    =12160         38 running   -               ns3-pvt.vlabs.ac.in=
    =12161         38 running   -               ns1-pub.vlabs.ac.in=
    =12165         41 running   -               pascal.vlabs.ac.in=
    =12169         31 running   -               ssh-tunnel.virtual-labs.ac.in=
    =12201         30 running   -               gateone.virtual-labs.ac.in=
    =12202         38 running   -               ns2-pub.virtual-labs.ac.in=
    =12206         57 running   10.4.12.206     community.virtual-labs.ac.in=
    =12221         38 running   -               ns4-pvt.virtual-labs.ac.in=
    =12236         25 running   -               stpi-router.virtual-labs.ac.in=
    =12237         29 running   -               stpi-proxy.virtual-labs.ac.in=
    =17896       2402 running   10.4.12.220     deploy.virtual-labs.ac.in=
** Containers on Base1
       288         78 running   -               feedback.base1.vlabs.ac.in
       290         78 running   -               outreach.base1.vlabs.ac.in
        23         47 running   -               analytics.base1.vlabs.ac.in   
      1001         27 running   -               router.base1.vlabs.ac.in
      1002         20 running   -               ansible.base1.vlabs.ac.in
      1003         16 running   -               ossec-server.base1.vlabs.ac.in
      1004         19 running   -               rsyslog.base1.vlabs.ac.in
      1005         38 running   -               privatedns.base1.vlabs.ac.in
      1006         38 running   -               publicdns.base1.vlabs.ac.in
      1007        500 running   -               reverseproxy.base1.vlabs.ac.in
      1008         18 running   -               nagios.base1.vlabs.ac.in
      1009         38 running   -               ads.base1.vlabs.ac.in
      1010         18 running   -               rsnapshot.base1.vlabs.ac.in
     12151         20 running   10.4.12.151     ca.virtual-labs.ac.in
       232         20 running   -               experiment-server.base1.vlabs.ac.in

* Base machines
   - Base1 - Staging 
   - Base2 - Docker by Medhamsh
   - Base3 - stpi & DNS server
   - Base4 - Testing environment
* Amazon
   - EC2 electric compute cloud, EC2 is a container on aws
   - VPC virtual private cloud 
| AWS       | Base Machines |
|-----------+---------------|
| EC2       | Openvz        |
|-----------+---------------|
| Instances | conainers     |
|-----------+---------------|
| VPC       | bridges       |
|-----------+---------------|
* Creating vagrantbox
  - 
* openvz template creation/adding
  - [[https://gitlab.com/vlead-systems/docs/blob/master/src/base-machines-docs/create-new-template-from-existing.org][Here]] is the gitlab link to create openvz template.
  - https://gitlab.com/vlead-systems/docs/blob/master/src/base-machines-docs/openvz-create-template.org  
* HTTP & HTTPS
  - HTTP - public & anyone can track or hack the site
  - HTTPS - Secure site, no one can hack the site.  
* CDAC
* Emacs
* Login from outside of iiit
  - Use the below command to login to ansible/base-machines outside
    IIIT-H.
    #+BEGIN_EXAMPLE
    ssh user@ssh-tunnel.vlabs.ac.in
    ssh user@196.52.32.133
    ssh -i aa1.pem vlead@ansible.vlabs.ac.in
    ssh root@<ip>/domain
    #+END_EXAMPLE
  - IAM - Identityt Access management
* Repositories
  - [[https://gitlab.com/vlead-systems/college-cloud/blob/master/src/labs-on-college-cloud/list-of-labs-in-college-cloud.org][Labs on College]]
  - [[https://gitlab.com/vlead-systems/cluster-automation/blob/exclude-ads-role/src/imp/installation-steps.org][Cluster-automation-exclude-ads-role]]  
  - [[https://gitlab.com/vlead-systems/systems-model/blob/include-ads-role/src/bootstrapping.org][Systems-model-include-ads-role]]  
  - [[https://gitlab.com/vlead-projects/aws-invoices][Aws-invoice]]
  - [[https://gitlab.com/vlead-systems/docs/blob/master/src/how-to/renewal-ssl.org][SSl Certificates]] 
  - [[https://gitlab.com/vlead-systems/docs/tree/master/src/how-to][Documentations-docs]]  
* OShardenning
** In Servers
   - Centos - osharden   
** In Services
   - Ubuntu - ubuntu harden
* Vlabs Servers & Sevices
** Router
   - Container ID 1001
   - This document describes the requirements, design and
     implementation of the Router Server. This server is the only access
     interface between the different nodes like DNS (private & public)
     and reverse-proxy in the network infrastructure with the external
     networks. 
   - A router is a networking device that forwards data packets
     between computer networks. It acts as a gateway to and for all other
     servers. The external requests from the different lab users would
     have to pass through the router server to reach the internal network
     nodes.
   - The router could be seen as device which functions to lock the
     internet away from your internal network infrastrucutre.  This means
     that if your internal nodes need to ask for something from the
     internet, they ask the router and vice versa.  In the current
     architecture, we are using Ansible scripts to configure the router
     server.These scripts are executed directly from the configuration
     server(Ansible Server).
   - [[https://gitlab.com/vlead-systems/systems-model/blob/include-ads-role/src/router.org][Here]] is the document on router. 
   - Ports on different servers are as below:
     #+BEGIN_EXAMPLE
     reverseproxy   -  80, 443
     DNS            -  53
     Backup server  - 2222
     Router+firewall-TCP 80 & 443-HTTP(s), UDP 53- DNS
     Outgoing       - TCP 80 & 443-HTTP(s), UDP 53-DNS, TCP 2222-SSH
     #+END_EXAMPLE
** Ansible/ Config server
   - Container Id 1002
   - [[https://gitlab.com/vlead-systems/systems-model/blob/include-ads-role/src/config-server.org][Here]] is the documnet on ansible server.
   - Configuration files of all the servers are located here.
   - It contains all the ansible-scripts to bring up the other nodes. The purpose
     of this server is to avoid manual configuration of nodes by team members. The
     mechanism ansible provides to configure other nodes is via ssh  
   - The configuration server will be able to ssh to other servers and lab
     instances/containers using key based authentication only since public key of
     configuration server will be placed in all other servers/nodes,
     instances/containers and itself also. Password based authentication is not
     allowed to this node
  - The services to register and de-register labs provided by the
    configuration server are also captured in the document.
  - Configuration server is one of the many other nodes in the
    cluster. Only IIIT IP range and management ip machines are
    allowed to ssh to root account of the configuration server.
  - The design of the firewall rules ensures that this server is
    accessible only via port 22.
  - The Configuration server accepts incoming connections on port 22
    only from IIIT IP range or management ip machines.
** osse-server
   - Container ID 1003
** public-dns
   - Container ID 1006
   - This document describes the requirements, design and
     implementation of the public Domain Name Server (DNS) .  This
     node is used to provide domain name resolution for all other
     servers in the cluster. This DNS will be the authoritative name
     server for the domain name “virtual-labs.ac.in” and
     “vlabs.ac.in”. The Public IP of this machine needs to be
     officially registered with ERNET to make this machine an
     authoritative name server for the domain.
   - The router is the only machine which would contact the public DNS
     for name resolution. The requests for name resolution come from
     the external networks (lab users) for resolving the names of the
     labs.
   - Public dns to router passes through port UDP 53.   
** Private-dns
   - Container ID 1005
   - This document describes the requirements, design and
     implementation of the private Domain Name System (DNS).  This
     server provides the domain name resolution for all other servers
     in the cluster.  This server resolves both the private zones
     (vlabs.ac.in and virtual-labs.ac.in) and the external zones
     (eg. gnu.org, google.com) for all other server
   - Private dns to other networks in cluster passess through port
     UDP 53.
** reverse proxy
   - Container ID 1007
   - This document describes the requirements, design and
     implementation of the Reverse Proxy server setup and AWStats. The
     server is configured using ansible scripts/playbooks.
   - Our cluster consist of many nodes. Reverse proxy is one of the
     main node in the cluster. All http and https requests external
     world are forwarded to reverse proxy to access the labs.
   - Log analyzer (AWStats) gives us lab user’s web trafic information
     such as number of visitors and visits, number of pages for a
     visit, etc. Analytics can be viewed on terminal and also in the
     browser.
   - Allow incoming connections on tcp ports 80 and 443 to accept the
     web requests coming from the router.
   - Allow outgoing connections on tcp port 80 to forward the
     client. And also required for yum. This requirement is fulfilled
     by <a href=”Firewall rules”>OUTPUT rule for 80 in firewall rules
     section
   - Allow outgoing connections on tcp port 443 for yum. This
     requirement is fulfilled by OUTPUT rule for 443 in firewall rules
     section
   - Stores analytics of each lab using AWStats (Logfile analyzer).
   - Revers proxy uses router IP as default gateway to reach the
     external world.
   - Forward the virtual hosts Custom(access), Error logs to rsyslog
     node.     
** nagios
   - Container ID 1008
   - This document describes the design and implementation of the
     Monitoring System - Nagios. Nagios is a monitoring tool for
     monitoring services of a system such as ssh service, cpu usage, ram
     usage and disk usage. Nodes to be monitored are configured as
     nrpe-client.
   - Nagios server sends email alerts in case of any critical situation
     inside nrpe-client node.
   - Monitor various services such as ssh, ping, http on all the system.
   - Allow incoming connections on TCP port 80.
   - Allow outgoing connections on TCP port 22.
   - Allow outgoing connections on TCP port 5666 for nrpe.
   - Run apache service.
   - Run nagios service.  
** rsnapshot
   - Container ID 1010.
   - It takes the timely backup of configuration files of all the
     seervers
   - This document describes the design and implementation of
     Rsnapshot Server. Rsnapshot node is configured to take timely
     backup of configuration files of various nodes in the cluster.
   - If a node is compromised due to any reason, the authenticity of
     the files in the node can not be relied. For this reason backup
     of the configuration files of various nodes are saved in a
     specific node of the cluster. To setup the nodes again these
     backups configuration files are referred.
   - Take periodic backup of various files on all the nodes in the
     cluster.
   - Take periodic backup of various files on local node in case the
     node is rsnapshot server itself.
   - Push weekly backups to an off site storage node, currently
     aws-backup.vlabs.ac.in located at IIIT-H.  
** rsyslog
   - Container ID 1004
   - The rsyslog server provides the support for building a central
     logging system, where a copy of the logs from the other nodes is
     forwarded to the rsyslog server for security purposes.  If a node is
     compromised then the attacker can potentially modify or delete the
     logs present on the compromised node.  This limits the usability of
     the locally stored logs on a node, after the node has been
     compromised.
   - Rsyslog service should run on UDP port 514 to accept log messages
     from clients. These log messages should be saved in different
     directories / files per client for easy reference.
** ads-server
   - Auto Deployment Service(ADS) is a service. The main job
     of the service is to deploy applications inside the
     cluster.
* Services
** Outreach portal ( outreach.vlabs.ac.in )
** analytics-server( stats.vlabs.ac.in )
** feedback.vlabs.ac.in
** Lab Data service (LDS)   
* Public & Private IP's
* Networking
* Ansible
*   
