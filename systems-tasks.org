#+Title: Systems Tasks List
#+Author: Sravanthi
#+Date: [2018-08-03 Fri]

* Introduction
  This document contains the list of tasks for a system engineer at
  vlead.
* List of Tasks
  - backup-config-files
  - Ernet Domain name Provider
    Login to Ernet to
  - NameCheap - SSL certificates  
  - [[https://gitlab.com/vlead-systems/docs/blob/master/src/how-to/renewal-ssl.org][SSL certificates]] - domain name provider need to renew everytime
    before its renew time.
  - vlead-projects/aws-invoices
  - Outreach-portal
  - Feedback-portal
  - Analytics   
* Admin Tasks
  - Custom in gmail groups??
  - Gmail a/c
  - Ldap
  - Github
  - Gitlab
  - bitbucket 
  - Public/private domain
  - *AWS*
    
** Passwords
   - Login to base1
   - Enter into 12151 container 
     #+BEGIN_EXAMPLE
     vzctl enter 12151
     su -
     #+END_EXAMPLE
   - sqiltepassword.txt - base machines passwords
   - To open password.txt give the encrypted key.
* Create vlabs gmail account
** User details
   - Ask a users to give their details such as
   - Name
   - Phone Number
   - Gmail account
   - Github & Gitlab handles	
** Vlabs gmail account 
   - Login to vlabs admin account
   - Select admin from the menu
   - Select users option in Admin console
   - Click on "+" button to create user.
   - Enter user information details and set password.
   - To delete a user, choose user and suspend. 
** Add user in vlead mailing groups
   - Select groups in Admin console
   - Choose a group, click on manage users in group
   - Enter user mail id and add.
   - To remove user from the group, select user and click on =Remove
     memeber=.
** List of vlead Mailing groups  
   - vlead-staff@vlabs.ac.in
   - vlead-employees@vlabs.ac.in
   - systems@vlabs.ac.in 
   - support@vlabs.ac.in 
   - engineers@vlabs.ac.in
* Create IAM user on AWS
  - Login with root a/c
  - click on services, select IAM under security, Identity &
    Compliance.
  - IAM dashboard is opened, click on users to create an IAM user
  - Add user & follow the steps accordingly.  
* LDAP(Lightweight Directory Access Protocol) account creation
** Ldap credentials access 
   - GLPi
   - Base machines
   - Redmine
   - community
   - Base3, Base4  
** Create ldap account for a user to login to base4
   - Login to LDAP server on base3 with ldap user credentials.
     #+BEGIN_EXAMPLE
     ssh modepusravanthi@10.4.12.23
     sudo su -
     vzctl enter 13165
     su -
     #+END_EXAMPLE
   - Change directory to ldif_files(LDAP Data Interchange Format).
   - LDIF conveys directory content as a set of records, one record
     for each object.
   - create a file  =ldif_files/add_user_with_password.ldif= and add the below lines to it:
     #+BEGIN_EXAMPLE
     dn: cn=<user-name>,ou=people,dc=virtual-labs,dc=ac,dc=in  
     objectClass: inetOrgPerson
     objectClass: posixAccount
     objectClass: shadowAccount
     cn: <user-name>
     sn: <last-name>
     gn: <first-name>
     mail: <email-id>
     ou: people
     displayName: <user-name>
     telephoneNumber: <mobile-number>
     postalAddress:  IIIT-H 
     #Posix and Shadow account related attributes
     uid: <user-name>
     uidNumber: <some UID number above 500>
     gidNumber: <some GID number above 500> (same for all the user as it is group id)
     homeDirectory: /home/<user-name>
     loginShell: /bin/bash
     gecos: <user-name>
     userPassword: <slappasswd generated SSHA hash>
     shadowLastChange: 0
     shadowMax: -1
     shadowWarning: 999999
     #+END_EXAMPLE
   - set password for the created user with the below command:
     #+BEGIN_EXAMPLE
     slappasswd
     #+END_EXAMPLE
   - It generates the password for the user.  
   - Edit the add_user_with_password.ldif file, paste the generate
     password into userPassword place.
   - Add the user with LDAP
     #+BEGIN_EXAMPLE
     ldapadd -x -D 'cn=root,dc=virtual-labs,dc=ac,dc=in' -W -f add_user_with_password.ldif
     #+END_EXAMPLE
** Login to LDAP on base4
   - ssh user@10.4.12.24
   - It asks password, type default password *vlead123* then it asks
     to change the password Enter login(LDAP) password, again give *vlead123*
   - Then give the new password and retype the new password.
   - Password is successfully set for the user.   
** Remove user from ldap
   - To remove a user's ldif file use below command and replace the
     text within < > with the LDAP user¡¯s information.
     #+BEGIN_EXAMPLE  
     ldapdelete -x -D "cn=root,dc=virtual-labs,dc=ac,dc=in" -W "cn=<user-name>,ou=people,dc=virtual-labs,dc=ac,dc=in"
     #+END_EXAMPLE 
** Add user in Ldap admin group - Base3
    - Create a file =ldif_files/user-to-admin-group.ldif-<data>=
    - Add the below lines to the file:
      #+BEGIN_EXAMPLE 
      dn: cn=admin,ou=groups,dc=virtual-labs,dc=ac,dc=in
      changetype: modify
      add: memberuid
      memberuid: medhamsh
      #+END_EXAMPLE 
    - Save the file and use the below command to add a user to admin group:
      #+BEGIN_EXAMPLE 
      ldapadd -x -D 'cn=root,dc=virtual-labs,dc=ac,dc=in' -W -f add_user_into-admin-group.ldif
      #+END_EXAMPLE 
** Remove user from vlead admin group
   - Create a file =ldif_files/remove_user_from-admin-group.ldif=. Add
     below lines and save the file.
     #+BEGIN_EXAMPLE 
     dn: cn=admin,ou=groups,dc=virtual-labs,dc=ac,dc=in
     changetype: modify
     delete: memberuid
     memberuid: <user-id>
     #+END_EXAMPLE
   - Run the following command to remove user from admin group
     #+BEGIN_EXAMPLE 
     ldapmodify -x -D "cn=root,dc=virtual-labs, dc=ac, dc=in" -W -f remove_user_group.ldif
     #+END_EXAMPLE 
   - Enter LDAP password to remove user  
** Reset password
   - create a file =ldif_files/reset_user_password.ldif=. Add below
     lines and save the file
     #+BEGIN_EXAMPLE
     dn: cn=<user-name>,ou=people,dc=virtual-labs,dc=ac,dc=in  
     changetype: modify
     replace: userPassword
     userPassword: <slappasswd generated SSHA hash>
     #+END_EXAMPLE  
   - Use below command to modify the user
     #+BEGIN_EXAMPLE
     ldapmodify -x -D "cn=root,dc=virtual-labs,dc=ac,dc=in" -W -f ldif_files/reset_user_password.ldif
     #+END_EXAMPLE
   - Enter ldap password (from passwords.txt)
   - Use below command to generate a new password
     #+BEGIN_EXAMPLE
     slappasswd
     #+END_EXAMPLE
   - Edit the reset_user_password.ldif file, paste the generate
     password into userPassword place.
** Modify user
   - ldapmodify -x -D "cn=root,dc=virtual-labs,dc=ac,dc=in" -W -f ldif_files/reset_user_password.ldif
   - Give github & gitlab access as vlead-staff & vlead organization
** Permissions for aws ansible 
   - Use below command to give permission for a user
     #+BEGIN_EXAMPLE
     chown -R <user>:engg /home/<user>/aa1.pem
     #+END_EXAMPLE
* Base1 access
  - Login to base1 and add user pub key in =.ssh/authorized_keys=
* Close the fixed issues 
    - Closing unnecessary/ fixed issues from gitlab systems-operations
      repository.
    - If the issue is fixed, close the issue. 
* Access to common folders
* OS installation
    - Configuration of a machine/system
    - Partition  
    - Installing Packages
    - Emacs  
* Deployment of lab/ service through ADS
    - First deploy the lab on base4(testing environment) through
      ADS. It creates a container on base4, we can check the given lab
      url.
    - If everything works fine then deploy the lab on
      base1(staging/production) using ADS.
    - It creates an AMI, Instance, volume and snapshot at AWS with the
      size, ID, type, IP address.
** Deployment on base1(staging), base4
   - Use below URL to deploy the lab on base4 & base1:
     #+BEGIN_EXAMPLE
     http://ads.base4.virtual-labs.ac.in/  - base4
     http://ads.base1.virtual-labs.ac.in/  - base1
     #+END_EXAMPLE
   - Ads main page is displayed, click on Login button.
   - It asks for gmail credentials.
   - After the successful authentication.
   - A page to submit lab-id, lab url is displayed.
   - Give lab-ID, githubURL of the lab and branch then click on submit
     button.
   - After submitting, the below steps are processed internally
     through the deployment.
   - Initially, it clones the repository in ads
   - Creates a contianer with - OStemplate, IP,hostname
   - Installs dependenices through labspec.json
   - Copy the repository from ads to contianer
   - Enter into container and run make.
   - Remove default file index.html from /var/www/html/
   - Then copy build folder to /var/www/html/
   - After the successfull deployment, it gives the Ipaddress.
   - Copy the given IP and paste it in the browser.
   - The lab will be displayed.  
** Deployment on Production
   - Login to ssh-tunnel with the below command:
     #+BEGIN_EXAMPLE
     ssh user@ssh-tunnel.vlabs.ac.in
     sudo su -
     #+END_EXAMPLE
   - Login to ansible from =ssh-tunnel= using =aa1.pem= key.
     #+BEGIN_EXAMPLE
     ssh -i aa1.pem vlead@ansible.vlabs.ac.in
     #+END_EXAMPLE
   - Login to ADS VM on Aws 
     #+BEGIN_EXAMPLE
     ssh root@10.100.1.9
     #+END_EXAMPLE
   - Change directory to =ovpl=
     #+BEGIN_EXAMPLE
     cd ovpl
     #+END_EXAMPLE
   - Start =manage_services=
     #+BEGIN_EXAMPLE
     ./manage_services.sh start LOGGER
     #+END_EXAMPLE
   - Provide email id in =/root/ovpl/src/ads-web-app/config.py=
   - Run app.py
     #+BEGIN_EXAMPLE
     python app.py &
     #+END_EXAMPLE
   - Browse the link http://ads.vlabs.ac.in:8080
   - Login to ads console page, provide the values in the fields and
     click on submit.
   - Check the ads server logs of deploying lab with the below command:
     #+BEGIN_EXAMPLE
     tail -f /root/log/ovpl.log
     #+END_EXAMPLE
   - After the deploying the lab, ads console page will give lab_id
     and Ipaddress.
   - Exit from ADS server as follows:
     #+BEGIN_EXAMPLE
     exit or ctrl+d
     #+END_EXAMPLE
   - The above above command takes to ansibel/config server
   - Go to git/systems-model/build/aws-code/
   - Update the common_vars with ipaddress and lab_id then save &
     close the file.
     #+BEGIN_EXAMPLE
     vim git/systems-model/build/aws-code/roles/common_vars/vars/
     #+END_EXAMPLE
   - Add DNS entries in VLEAD DNS (Public and Private). These DNS
     servers are running on base3 machine.
   - Login to =Base3= machine using  LDAP credentials
   - Login to ns1-pub container and update dns entries with ipaddress
     and lab_id.
     #+BEGIN_EXAMPLE
     cd /var/named/virtual-labs.ac.in.forward
     #+END_EXAMPLE
   - save and exit from the file.
   - Restart named service
     #+BEGIN_EXAMPLE
     service named reload
     #+END_EXAMPLE
   - Exit from the public dns container.
   - Login to private dns 
     #+BEGIN_EXAMPLE
     vzctl enter 12160
     #+END_EXAMPLE
   - Add dns entries in /var/named/virtual-labs.ac.in.forward
   - save and exit.
   - Restart named service
     #+BEGIN_EXAMPLE
     service named reload
     #+END_EXAMPLE
   - Add virtualhost on production reverse proxy at:
     #+BEGIN_EXAMPLE
     vim /etc/httpd/conf.d/virtualhosts.conf
     #+END_EXAMPLE
** Updating the existing lab sources
   - Login to ssh-tunnel with the below command:
     #+BEGIN_EXAMPLE
     ssh user@ssh-tunnel.vlabs.ac.in
     sudo su -
     #+END_EXAMPLE
   - Login to ansible/config serever from =ssh-tunnel= using =aa1.pem=
     key.
     #+BEGIN_EXAMPLE
     ssh -i aa1.pem vlead@ansible.vlabs.ac.in
     #+END_EXAMPLE
   - Login to lab VM
     #+BEGIN_EXAMPLE
     ssh root@<lab-vm-private-ip>
     or
     ssh root@<lab-fqdn>
     #+END_EXAMPLE
   - Go to the lab repository location
     #+BEGIN_EXAMPLE
     cd /root/labs/<lab-repo>
     #+END_EXAMPLE
   - Pull the changes
     #+BEGIN_EXAMPLE
     git pull
     #+END_EXAMPLE
   - Run make
     #+BEGIN_EXAMPLE
     make
     #+END_EXAMPLE
   - Rsync the build files to /var/www/  
     #+BEGIN_EXAMPLE
     rsync -avr build/* /var/www/
     #+END_EXAMPLE
   - Lab sources are update with the latest updates.  
** Assigning Domain Name in base3-dns
   - Login to base3 
     #+BEGIN_EXAMPLE
     ssh ldap@10.4.12.23
     vzctl enter <public-dns>(ns1-pub)
     #+END_EXAMPLE
   - vim /var/named/virtual-labs.conf
   - Add public entry (domain name)
   - Run the below command to start named service.
     #+BEGIN_EXAMPLE
     service reload named
     #+END_EXAMPLE 
   - ssh root@reverseproxy.vlabs.ac.in
   - vim /etc/httpd/conf.d/virtual-hosts.conf
   - service httpd relaod
   - ssh root@public-dns
   - vi /var/named/vlabs.ac.in.forward/ =virtual-labs.ac.in.forward=
   - login to base3, enter into ns1-pub  
   - vi /var/named/vlabs.ac.in.forward/ =virtual-labs.ac.in.forward=
     #+BEGIN_EXAMPLE
     add domain name
     #+END_EXAMPLE
   - Cert files
   - Production - main - base3
     #+BEGIN_EXAMPLE
     base3
     ns1-pub -> vim /var/named/virtual-labs.ac.in.forward  
     ns1-pub -> vim /var/named/vlabs.ac.in.forward
     service named reload
     #+END_EXAMPLE     
   - Ansible  - Production
   - Check route -n in the following servers:
     #+BEGIN_EXAMPLE
     public-dns
     private-dns
     reverse-proxy
     #+END_EXAMPLE
* Creating an OPenVZ container
    - One should install OpenVZ on centos/ubuntu.
    - Commands to create and start openvz container:
      #+BEGIN_EXAMPLE  
      vzctl create <CTID> --ostemplate <ubuntu-14.04-X86_64> --ipaddress <10.4.12.30> --hostname <xxx.vlabs.ac.in>
      vzctl start <CTID>
      vzctl enter <CTID>
      #+END_EXAMPLE  
    - Commands to stop and delete a container
      #+BEGIN_EXAMPLE  
      vzctl stop <CTID>
      vzctl destroy <CTID>
      #+END_EXAMPLE  
* ADS Autodeployment service
    - Download ads vagrantbox from [[http://files.vlabs.ac.in/downloads/vagrant-boxes/ads-on-centos.box][here]]. 
    - Add downloaded vagrantbox to the vagrantbox list
    - create a folder and run =vagrant init= inside the folder.
    - It generates a =Vagrantfile=  
    - Open vagrant file and update =config.vim.box= as the the folder
      name which was created earlier.
    - Uncomment the =private_network= line the the same file.
    - Save and exit from the file.
    - Change directory to the folder and type below command to start and
      enter into the ads vagranbox.
      #+BEGIN_EXAMPLE
      vagrant up
      vagrant ssh
      #+END_EXAMPLE
    - Create google OAuthcredentials, give the client ID and secret
      key in =/root/ovpl/src/ads-web-app-config.py= and save the file.
    - Make appropriate changes and run the below scripts
      #+BEGIN_EXAMPLE
      ./managescript.sh
      python app.py & in ads-web-app
      #+END_EXAMPLE
* College Cloud
    - Setup college cloud
    - cluster setup is college cloud
* IRC
   - IRc channel on base3 container ID 16302
   - Install and setup supybot
   - Create a user vlead and configure supybot inside the user.
   - Run "supybot vlead-logging.conf &" whenever IRC stops backing up the logs  
* Migrating containers 
  - Migration is basically to move  one container from one server/node
    to another server/node.
  - Login to base4 choose the container you want to migrate from
    base4 to base3 and run the below command:
    #+BEGIN_EXAMPLE     
    vzmigrate <basemachine_ip> <CTID>
    Ex: vzmigrate 10.4.12.24 41
    #+END_EXAMPLE  
* Taking dump
  - Login to ssh-tunnel
    #+BEGIN_EXAMPLE 
    ssh user@ssh-tunnel.vlabs.ac.in
    #+END_EXAMPLE 
  - Login to outreach-portal
    #+BEGIN_EXAMPLE 
    ssh root@outreach.vlabs.ac.in
    #+END_EXAMPLE 
  - Check outreach dump and exit from outreach
  - Copy dump from outreach to vlead@ansible 
    #+BEGIN_EXAMPLE 
    rsync -avz --progress root@10.100.3.13:/root/<file> .
    #+END_EXAMPLE 
  - Above command copies dump file to vlead@ansible.
  - Copy dump to any base machines.
    #+BEGIN_EXAMPLE 
    rsync -avz --progress outreach-backup-08-10-2018.sql <user>@10.4.12.24:/home/<user>/
    #+END_EXAMPLE 
  - Then we can copy to anu base machine.  
* Docker
* DNS
   - Domain Name Service (DNS) is an Internet service that maps IP
     addresses and fully qualified domain names (FQDN) to one
     another. In this way, DNS alleviates the need to remember IP
     addresses. Computers that run DNS are called name servers.
   - sudo apt install bind9
   - sudo apt install dnsutils
   - The DNS configuration files are stored in the /etc/bind
     directory. The primary configuration file is /etc/bind/named.conf
   - Login to base4 as below:
     #+BEGIN_EXAMPLE 
     ssh <user>@10.4.12.24
     #+END_EXAMPLE 
   - Login to the public-dns container as below:
     #+BEGIN_EXAMPLE 
     vzctl enter 1006
     #+END_EXAMPLE 
   - Open the file =/var/named/base4.virual-labs.ac.in.forward= and
     =/var/named/base4.vlabs.ac.in.forward=
   - Add the domain name of the lab to make the lab public.  
* Bootstraping
  - Setting up the cluster using bootstrapping steps
  - The bootstraping steps configures the router, ansible, rsyslog,
      reverse-proxy, nagios,rsnapshot,ADS, privatedns, publicdns,
      ossec server manually.
  -  
* Cluster automation
    - The cluster automation implements the following with the
      =bootstrap.sh= shell script:
      #+BEGIN_EXAMPLE
      basic machine setup
      creates cluster containers
      router
      ansible/config server
      ossec-server
      rsyslog  server
      private-dns server
      public-dns server 
      reverse-proxy server
      nagios server
      rsnapshot server
      ADS service
      Main Playbook
      #+END_EXAMPLE
*** Steps for cluster automation      
    - Install a minimal centos in virtual box with the following
      configuration:
      #+BEGIN_EXAMPLE 
      RAM 1GB
      #+END_EXAMPLE 
    - Should be connected to the Lan cable 
    - Change the Network settings from =NAT to Bridge Adapter= and
      =Display= to minimum =50MB=.
    - Login to machine with root credentials.
    - Export network proxy and type =dhclient -v= to make the internet
      working state.
    - Install git with the below command:
      #+BEGIN_EXAMPLE
      yum install -y git
      #+END_EXAMPLE
    - Clone the cluster-automation repository
      #+BEGIN_EXAMPLE
      git clone https://gitlab.com/vlead-systems/cluster-automation
      #+END_EXAMPLE
    - Change directory to cluster-automation
    - Run make
    - Take three LAN IP's for hostmachine, router,config server  
    - **Edit the file
      ~/cluster-automation/build/code/imp/roles/common_vars/vars/main.yml
      and make the following changes:
      #+BEGIN_EXAMPLE
      hostmachine_ip: <>
      router_ip: <>
      config_server_ip: <>
      #+END_EXAMPLE
    - Change consumer key and consumer secret in the above file.  
    - Run bootstrap.sh file from cluster-automation directory.
    - After running the script all the servers are properly configured.

* Tasks to be Learn 
    - base machines down - solution   
    - vlabs-about
    - vlabs-dev-pages
    - Vlabs-web-pages
    - Nagios
    - Outreach portal
    - Feedback portal
    - All passwords
    - Experiment server
    - Migrating instances from t2.micro to t2.nano
    - SSL Certificates
    - vlabs Wiki
    - Servers Size increment
    - Server backup dump
    - reverseproxy - 80%
    - Nagios
    - Vagrant
    - Kernal
** Fixing localhost issue
   - Open terminal and run below command
     #+BEGIN_EXAMPLE
     sudo netstat -ltnp | grep ':80'
     #+END_EXAMPLE
   - Aboe  command gives the below output
     #+BEGIN_EXAMPLE
     tcp        0      0 127.0.0.1:80            0.0.0.0:*               LISTEN      1554/aolserver4-nsd
     #+END_EXAMPLE
   - Then run the below to kill the tcp
     #+BEGIN_EXAMPLE
     sudo kill -9 1554
     #+END_EXAMPLE
   - Now the localhost works fine.  
* Important containers running on base3, base1
** Important contianers running on Base 3 
|   134 | 24 running | 10.4.12.134 | files.vlabs.ac.in              |
|-------+------------+-------------+--------------------------------|
|   135 | 45 running | 10.4.12.135 | glpi.vlabs.ac.in               |
|-------+------------+-------------+--------------------------------|
| 12052 | - stopped  |  10.4.12.52 | cse04-iiith.virtual-labs.ac.in |
|-------+------------+-------------+--------------------------------|
| 12053 | 43 running |  10.4.12.53 | cse06-iiith.virtual-labs.ac.in |
|-------+------------+-------------+--------------------------------|
| 12054 | 41 running |  10.4.12.54 | cse07-iiith.vlabs.ac.in        |
|-------+------------+-------------+--------------------------------|
| 12055 | - stopped  |  10.4.12.55 | cse09-iiith.vlabs.ac.in        |
|-------+------------+-------------+--------------------------------|
| 12056 | 43 running |  10.4.12.56 | cse05-iiith.vlabs.ac.in        |
|-------+------------+-------------+--------------------------------|
| 12057 | 43 running |  10.4.12.57 | cse13-iiith.virtual-labs.ac.in |
|-------+------------+-------------+--------------------------------|
| 12058 | 24 running |  10.4.12.58 | cse16-iiith.virtual-labs.ac.in |
|-------+------------+-------------+--------------------------------|
| 12059 | 43 running |  10.4.12.59 | cse17-iiith.virtual-labs.ac.in |
|-------+------------+-------------+--------------------------------|
| 12060 | 43 running |  10.4.12.60 | cse21-iiith.virtual-labs.ac.in |
|-------+------------+-------------+--------------------------------|
| 12061 | 43 running |  10.4.12.61 | cse24-iiith.vlabs.ac.in        |
|-------+------------+-------------+--------------------------------|
| 12062 | 43 running |  10.4.12.62 | cse30-iiith.vlbs.ac.in         |
|-------+------------+-------------+--------------------------------|
| 12063 |            |             |                                |
|-------+------------+-------------+--------------------------------|
|       |            |             |                                |
     12061         43 running   10.4.12.61      cse24-iiith.virtual-labs.ac.in
     12062         43 running   10.4.12.62      cse30-iiith.virtual-labs.ac.in
    =12063          - stopped   -               repo-backup.vlabs.ac.in=
     12064         43 running   10.4.12.64      eerc02-iiith.virtual-labs.ac.in
     12065          - stopped   10.4.12.65      eerc04-iiith.virtual-labs.ac.in
     12066         43 running   10.4.12.66      eerc05-iiith.virtual-labs.ac.in
     12067          - stopped   10.4.12.67      cse23-iiith.virtual-labs.ac.in
     12068         43 running   10.4.12.68      cse10-iitkgp.virtual-labs.ac.in
     12069         37 running   10.4.12.69      civil13-iitb.virtual-labs.ac.in
     12070          - stopped   10.4.12.70      ccnsb01-iiith.virtual-labs.ac.in
     12071         41 running   10.4.12.71      ccnsb02-iiith.virtual-labs.ac.in
     12072          - stopped   10.4.12.72      ccnsb03-iiith.virtual-labs.ac.in
     12073         43 running   10.4.12.73      ccnsb04-iiith.virtual-labs.ac.in
     12074         24 running   10.4.12.74      ccnsb05-iiith.virtual-labs.ac.in
     12075          - stopped   10.4.12.75      ccnsb07-iiith.virtual-labs.ac.in
     12079         24 running   10.4.12.79      mech01-iitg.virtual-labs.ac.in
     12080          - stopped   10.4.12.80      eee06-dei.virtual-labs.ac.in
    =12081         20 running   -               aws-backup.virtual-labs.ac.in=
    =12159         33 running   -               http.virtual-labs.ac.in=
    =12160         38 running   -               ns3-pvt.vlabs.ac.in=
    =12161         38 running   -               ns1-pub.vlabs.ac.in=
    =12165         41 running   -               pascal.vlabs.ac.in=
    =12169         31 running   -               ssh-tunnel.virtual-labs.ac.in=
    =12201         30 running   -               gateone.virtual-labs.ac.in=
    =12202         38 running   -               ns2-pub.virtual-labs.ac.in=
    =12206         57 running   10.4.12.206     community.virtual-labs.ac.in=
    =12221         38 running   -               ns4-pvt.virtual-labs.ac.in=
    =12236         25 running   -               stpi-router.virtual-labs.ac.in=
    =12237         29 running   -               stpi-proxy.virtual-labs.ac.in=
    =17896       2402 running   10.4.12.220     deploy.virtual-labs.ac.in=
** Containers on Base1
       288         78 running   -               feedback.base1.vlabs.ac.in
       290         78 running   -               outreach.base1.vlabs.ac.in
        23         47 running   -               analytics.base1.vlabs.ac.in   
      1001         27 running   -               router.base1.vlabs.ac.in
      1002         20 running   -               ansible.base1.vlabs.ac.in
      1003         16 running   -               ossec-server.base1.vlabs.ac.in
      1004         19 running   -               rsyslog.base1.vlabs.ac.in
      1005         38 running   -               privatedns.base1.vlabs.ac.in
      1006         38 running   -               publicdns.base1.vlabs.ac.in
      1007        500 running   -               reverseproxy.base1.vlabs.ac.in
      1008         18 running   -               nagios.base1.vlabs.ac.in
      1009         38 running   -               ads.base1.vlabs.ac.in
      1010         18 running   -               rsnapshot.base1.vlabs.ac.in
     12151         20 running   10.4.12.151     ca.virtual-labs.ac.in
       232         20 running   -               experiment-server.base1.vlabs.ac.in

* Base machines
   - Base1 - Staging 
   - Base2 - Docker by Medhamsh
   - Base3 - stpi & DNS server
   - Base4 - Testing environment
* Amazon
   - EC2 electric compute cloud, EC2 is a container on aws
   - VPC virtual private cloud 
| AWS       | Base Machines |
|-----------+---------------|
| EC2       | Openvz        |
|-----------+---------------|
| Instances | conainers     |
|-----------+---------------|
| VPC       | bridges       |
|-----------+---------------|
* Creating vagrantbox
  - 
* openvz template creation/adding
  - [[https://gitlab.com/vlead-systems/docs/blob/master/src/base-machines-docs/create-new-template-from-existing.org][Here]] is the gitlab link to create openvz template.
  - https://gitlab.com/vlead-systems/docs/blob/master/src/base-machines-docs/openvz-create-template.org
  - increase disk size using below command:
    #+BEGIN_EXAMPLE
    vzctl set <CTID> --diskspace <G:G> --save
    #+END_EXAMPLE
* HTTP & HTTPS
  - HTTP - public & anyone can track or hack the site
  - HTTPS - Secure site, no one can hack the site.  
* CDAC
  - Fixing the server issues
* Emacs
* Login from outside of iiit
  - Use the below command to login to ansible/base-machines from
    outside IIIT-H.
    #+BEGIN_EXAMPLE
    ssh user@ssh-tunnel.vlabs.ac.in
    # ssh user@196.52.32.133
    ssh -i aa1.pem vlead@ansible.vlabs.ac.in
    ssh root@<ip>/domain
    #+END_EXAMPLE
  - IAM - Identityt Access management
  - Do sudo su - after login to ssh tunnel
** Access to ssh tunnel
   - To give access to ssh tunnel for a user follow the below steps:
     #+BEGIN_EXAMPLE
     rsync /home/modepusravanthi/aa1.pem /home/user/
     chown -R user:engg /home/user/aa1.pem
     #+END_EXAMPLE
* Repositories
  - [[https://gitlab.com/vlead-systems/college-cloud/blob/master/src/labs-on-college-cloud/list-of-labs-in-college-cloud.org][Labs on College]]
  - [[https://gitlab.com/vlead-systems/cluster-automation/blob/exclude-ads-role/src/imp/installation-steps.org][Cluster-automation-exclude-ads-role]]  
  - [[https://gitlab.com/vlead-systems/systems-model/blob/include-ads-role/src/bootstrapping.org][Systems-del-include-ads-role]]  
  - [[https://gitlab.com/vlead-projects/aws-invoices][Aws-invoice]]
  - [[https://gitlab.com/vlead-systems/docs/blob/master/src/how-to/renewal-ssl.org][SSl Certificates]] 
  - [[https://gitlab.com/vlead-systems/docs/tree/master/src/how-to][Documentations-docs]]  
* OShardenning
** In Servers
   - Centos - osharden   
** In Services
   - Ubuntu - ubuntu harden
* Vlabs Servers & Sevices
** Router
   - Container ID 1001
   -   
   - This document describes the requirements, design and
     implementation of the Router Server. This server is the only access
     interface between the different nodes like DNS (private & public)
     and reverse-proxy in the network infrastructure with the external
     networks. 
   - A router is a networking device that forwards data packets
     between computer networks. It acts as a gateway to and for all other
     servers. The external requests from the different lab users would
     have to pass through the router server to reach the internal network
     nodes.
   - The router could be seen as device which functions to lock the
     internet away from your internal network infrastrucutre.  This means
     that if your internal nodes need to ask for something from the
     internet, they ask the router and vice versa.  In the current
     architecture, we are using Ansible scripts to configure the router
     server.These scripts are executed directly from the configuration
     server(Ansible Server).
   - [[https://gitlab.com/vlead-systems/systems-model/blob/include-ads-role/src/router.org][Here]] is the document on router. 
   - Ports on different servers are as below:
     #+BEGIN_EXAMPLE
     reverseproxy   -  80, 443
     DNS            -  53
     Backup server  - 2222
     Router+firewall-TCP 80 & 443-HTTP(s), UDP 53- DNS
     Outgoing       - TCP 80 & 443-HTTP(s), UDP 53-DNS, TCP 2222-SSH
     #+END_EXAMPLE
** Ansible/ Config server
   - Container Id 1002
   - Stores all other servers configuration files.  
   - [[https://gitlab.com/vlead-systems/systems-model/blob/include-ads-role/src/config-server.org][Here]] is the documnet on ansible server.
   - Configuration files of all the servers are located here.
   - It contains all the ansible-scripts to bring up the other nodes. The purpose
     of this server is to avoid manual configuration of nodes by team members. The
     mechanism ansible provides to configure other nodes is via ssh  
   - The configuration server will be able to ssh to other servers and lab
     instances/containers using key based authentication only since public key of
     configuration server will be placed in all other servers/nodes,
     instances/containers and itself also. Password based authentication is not
     allowed to this node
  - The services to register and de-register labs provided by the
    configuration server are also captured in the document.
  - Configuration server is one of the many other nodes in the
    cluster. Only IIIT IP range and management ip machines are
    allowed to ssh to root account of the configuration server.
  - The design of the firewall rules ensures that this server is
    accessible only via port 22.
  - The Configuration server accepts incoming connections on port 22
    only from IIIT IP range or management ip machines.
** osse-server
   - Container ID 1003
** public-dns
   - Container ID 1006
   - Stores the domain names of all the applications/labs etc. 
   - This document describes the requirements, design and
     implementation of the public Domain Name Server (DNS) .  This
     node is used to provide domain name resolution for all other
     servers in the cluster. This DNS will be the authoritative name
     server for the domain name “virtual-labs.ac.in” and
     “vlabs.ac.in”. The Public IP of this machine needs to be
     officially registered with ERNET to make this machine an
     authoritative name server for the domain.
   - The router is the only machine which would contact the public DNS
     for name resolution. The requests for name resolution come from
     the external networks (lab users) for resolving the names of the
     labs.
   - Public dns to router passes through port UDP 53.   
** Private-dns
   - Container ID 1005
   - This document describes the requirements, design and
     implementation of the private Domain Name System (DNS).  This
     server provides the domain name resolution for all other servers
     in the cluster.  This server resolves both the private zones
     (vlabs.ac.in and virtual-labs.ac.in) and the external zones
     (eg. gnu.org, google.com) for all other server
   - Private dns to other networks in cluster passess through port
     UDP 53.
** reverse proxy
   - Container ID 1007
   - All the communication passes through reverse proxy  
   - This document describes the requirements, design and
     implementation of the Reverse Proxy server setup and AWStats. The
     server is configured using ansible scripts/playbooks.
   - Our cluster consist of many nodes. Reverse proxy is one of the
     main node in the cluster. All http and https requests external
     world are forwarded to reverse proxy to access the labs.
   - Log analyzer (AWStats) gives us lab user’s web trafic information
     such as number of visitors and visits, number of pages for a
     visit, etc. Analytics can be viewed on terminal and also in the
     browser.
   - Allow incoming connections on tcp ports 80 and 443 to accept the
     web requests coming from the router.
   - Allow outgoing connections on tcp port 80 to forward the
     client. And also required for yum. This requirement is fulfilled
     by <a href=”Firewall rules”>OUTPUT rule for 80 in firewall rules
     section
   - Allow outgoing connections on tcp port 443 for yum. This
     requirement is fulfilled by OUTPUT rule for 443 in firewall rules
     section
   - Stores analytics of each lab using AWStats (Logfile analyzer).
   - Revers proxy uses router IP as default gateway to reach the
     external world.
   - Forward the virtual hosts Custom(access), Error logs to rsyslog
     node.     
** nagios
   - Container ID 1008
   - Monitors the ansible,private-dns, public-dns, reverse-proxy,
     router & rsyslog servers.
   - This document describes the design and implementation of the
     Monitoring System - Nagios. Nagios is a monitoring tool for
     monitoring services of a system such as ssh service, cpu usage, ram
     usage and disk usage. Nodes to be monitored are configured as
     nrpe-client.
   - Nagios server sends email alerts in case of any critical situation
     inside nrpe-client node.
   - Monitor various services such as ssh, ping, http on all the system.
   - Allow incoming connections on TCP port 80.
   - Allow outgoing connections on TCP port 22.
   - Allow outgoing connections on TCP port 5666 for nrpe.
   - Run apache service.
   - Run nagios service.  
** rsnapshot
   - Container ID 1010.
   - It takes the timely backup of configuration files of all the
     seervers
   - This document describes the design and implementation of
     Rsnapshot Server. Rsnapshot node is configured to take timely
     backup of configuration files of various nodes in the cluster.
   - If a node is compromised due to any reason, the authenticity of
     the files in the node can not be relied. For this reason backup
     of the configuration files of various nodes are saved in a
     specific node of the cluster. To setup the nodes again these
     backups configuration files are referred.
   - Take periodic backup of various files on all the nodes in the
     cluster.
   - Take periodic backup of various files on local node in case the
     node is rsnapshot server itself.
   - Push weekly backups to an off site storage node, currently
     aws-backup.vlabs.ac.in located at IIIT-H.  
** rsyslog
   - Container ID 1004
   - Takes backup of all the servers  
   - The rsyslog server provides the support for building a central
     logging system, where a copy of the logs from the other nodes is
     forwarded to the rsyslog server for security purposes.  If a node is
     compromised then the attacker can potentially modify delete the
     logs present on the compromised node.  This limits the usability of
     the locally stored logs on a node, after the node has been
     compromised.
   - Rsyslog service should run on UDP port 514 to accept log messages
     from clients. These log messages should be saved in different
     directories / files per client for easy reference.
** ads-server
   - Auto Deployment Service(ADS) is a service. The main job
     of the service is to deploy applications inside the
     cluster.
* Services
** Outreach portal ( outreach.vlabs.ac.in )
** analytics-server( stats.vlabs.ac.in )
** feedback.vlabs.ac.in
** Lab Data service (LDS)   
* Public & Private IP's
  - PortsWell
  - Known Ports
  - There are many others, but these are some of the more 
    popular ones
  - USC CSCI 201L
    
   |  20 | FTP data    |
   |-----+-------------|
   |  21 | FTP control |
   |-----+-------------|
   |  22 | SSH         |
   |-----+-------------|
   |  23 | Telnet      |
   |-----+-------------|
   |  25 | SMTP        |
   |-----+-------------|
   |  53 | DNS         |
   |-----+-------------|
   |  80 | HTTP        |
   |-----+-------------|
   | 143 | IMAP        |
   |-----+-------------|
   | 443 | HTTPS       |
   |-----+-------------|
 
*Virginia*
router pub ip  - 54.85.93.7     pvt ip - 10.100.1.1
ansible pub-ip - 52.4.150.142   pvt ip - 10.100.1.2

*Mumbai*
ansible pub-ip - 13.232.165.229
router pub-ip  - 35.154.150.192
* Networking
* Ansible
  - Ansible is simple open source IT engine which automates
    application deployment, intra service orchestration, cloud
    provisioning and many other IT tools.
* Firewall
  - Follow the below step to install iptables-persistent in Ubuntu-16.04 LTS OS
    | $ sudo apt-get install -y iptables-persistent |
  - Add a rule to block all SSH traffic (port 22) except for your IP
    | $ sudo iptables -A INPUT -p tcp --dport 22 -j DROP
  - Add a rule to block all HTTP traffic (port 80) except for your IP
    | $ sudo iptables -A INPUT -p tcp --dport 80 -j DROP
  - To Check the current firewall rules in machine
    | $ sudo iptables -L
  - To add above mentioned firewall rules into /etc/iptables/rules.v4 file and restart the iptables-persistent
    | $ sudo service iptables-persistent restart
** Reference
   1. Deny-all-incoming-connections-with-iptables
   2. Iptables-to-block-all-ssh-traffic-port-22-except-for-your-ip/
   3. Linux-iptables-4-block-all-incoming-traffic-but-allow-ssh.html
   4. Iptables-the-absolute-minimum-for-a-laptop-885889/
* Migrated instances from virginia to mumbai
  - vlabs-about.vlabs.ac.in
  - footer.vlabs.ac.in
  - ansible.vlabs.ac.in
  - lds.vlabs.ac.in  

locuz-vlead-iiith
kamal.das@locuz.com
* Changes made in the public dns
  - changes made in base 3 ns1-pub
  - in aws pulic-dns   
* Iptables
  - Different services is used for different protocols as:
    #+BEGIN_EXAMPLE
    iptables applies to IPv4.
    ip6tables applies to IPv6.
    arptables applies to ARP.
    ebtables applies to Ethernet frames..
    #+END_EXAMPLE
  - IPTables main files are:
    #+BEGIN_EXAMPLE
    /etc/init.d/iptables – init script to start|stop|restart and save rulesets.
    /etc/sysconfig/iptables – where Rulesets are saved.
    /sbin/iptables – binary.
    #+END_EXAMPLE
  - There are at present three tables.
    #+BEGIN_EXAMPLE
    Filter
    NAT
    Mangle
    #+END_EXAMPLE    
  - At present, there are total four chains:
    #+BEGIN_EXAMPLE 
    INPUT : Default chain originating to system.
    OUTPUT : Default chain generating from system.
    FORWARD : Default chain packets are send through another interface.
    RH-Firewall-1-INPUT : The user-defined custom chain.
    #+END_EXAMPLE 
  - Steps to manage iptable firewall:
    #+BEGIN_EXAMPLE
    # /etc/init.d/iptables start 
    # /etc/init.d/iptables stop
    # /etc/init.d/iptables restart
    #+END_EXAMPLE
* Apache not working
  - Use below command to list the tcp
    #+BEGIN_EXAMPLE    
    sudo netstat -ltnp | grep ':80'
    #+END_EXAMPLE  
  - Kill the existing tcp 
    #+BEGIN_EXAMPLE    
    sudo kill -9 <tcp>
    #+END_EXAMPLE    
  - Start apache
    #+BEGIN_EXAMPLE    
    service apache2 start
    #+END_EXAMPLE 

* Zimbra Installation
  - Require Java6 to install zimbra
* Outreach Portal Deployment
  - Login to AWS Outreach portal
  - Take backup of the existing "/var/www/" files to backups folder.
  - Change directory to /root/labs/outreach/  
  - Take database dump with the below command:
    #+BEGIN_EXAMPLE
    mysql -u root -p outreach > outreach-bkp-<date>.sql
    #+END_EXAMPLE
  - Change branch to master
  - Pull the latest sources using below command:
    #+BEGIN_EXAMPLE
    git pull
    #+END_EXAMPLE
  - Run make
  - Copy the build/code/* to /var/www/ using below command:
    #+BEGIN_EXAMPLE
    cp -R build/code/* /var/www/
    #+END_EXAMPLE
  - Change permissions using below command:
    #+BEGIN_EXAMPLE
    chmod -R 755 /var/www/
    #+END_EXAMPLE
  - Create Uploads directory using the below command:
    #+BEGIN_EXAMPLE
    mkdir /var/www/src/static/uploads
    #+END_EXAMPLE
  - Give permissions for the above file:
    #+BEGIN_EXAMPLE
    chmod -R 777 /var/www/src/static/uploads
    #+END_EXAMPLE
  - Copy the backup files (which are taken in the beginning) to
    /var/www/src/static/uploads/
  - Check src/config.py file (Auth data)
  - Update the key for map in =/var/src/template/layout.html=  
  - Start the apache2 server using below command:
    #+BEGIN_EXAMPLE
    service apache2 start
    #+END_EXAMPLE
** Mysql commands 
   - Login to mysql
     #+BEGIN_EXAMPLE
     mysql -u root -p 
     #+END_EXAMPLE
   - Enter password *root*
   - Use below command to use database:
     #+BEGIN_EXAMPLE
     EX: use <database-name>
     use outreach
     #+END_EXAMPLE
   - Use below command to select user:
     #+BEGIN_EXAMPLE
     select * from users where id=1;
     #+END_EXAMPLE
   - To update the user email use the below command:
     #+BEGIN_EXAMPLE
     update users set email='<mail-id>' where id=1;
     #+END_EXAMPLE
   - Then start the apache2 service as below:
     #+BEGIN_EXAMPLE
     service apache2 start
     #+END_EXAMPLE
